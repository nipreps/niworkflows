docs_deploy: &docs
  docker:
    - image: node:8.10.0
  steps:
    - run:
        name: Check whether this is the original repo
        command: |
          if [[ "$CIRCLE_PROJECT_USERNAME" != "nipreps" ]]; then
              echo "Not in nipreps/niworkflows - skipping docs deploy."
              circleci step halt
          fi
    - checkout
    - attach_workspace:
        at: docs/_build
    - run:
        name: Disable jekyll builds
        command: touch docs/_build/html/.nojekyll
    - run:
        name: Install and configure dependencies
        command: |
          npm install -g --silent gh-pages@2.0.1
          git config user.email "nipreps@gmail.com"
          git config user.name "Documentation Push"
    - add_ssh_keys:
        fingerprints:
          - "c8:a8:55:7d:1e:08:92:c2:86:29:7b:b4:4b:88:24:51"
    - run:
        name: Deploy docs to gh-pages branch
        command: gh-pages --dotfiles --message "doc(update) [skip ci]" --dist docs/_build/html

version: 2
jobs:
  build:
    machine:
      image: ubuntu-1604:202007-01
    working_directory: /tmp/src/niworkflows
    environment:
      TZ: "/usr/share/zoneinfo/America/Los_Angeles"
      SCRATCH: "/scratch"
    steps:
      - restore_cache:
          keys:
            - build-v1-{{ .Branch }}-{{ epoch }}
            - build-v1-{{ .Branch }}-
            - build-v1-master-
            - build-v1-
          paths:
            - /tmp/docker
            - /tmp/images
      - run:
          name: Docker authentication
          command: |
            if [[ -n $DOCKER_PASS ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
            fi
      - run:
          name: Set up Docker registry
          command: |
            if [[ -f /tmp/images/registry.tar.gz ]]; then
              echo "Loading saved registry image"
              docker load < /tmp/images/registry.tar.gz
            else
              echo "Pulling registry image from DockerHub"
              docker pull registry:2
              mkdir -p /tmp/images
              docker save registry:2 | gzip > /tmp/images/registry.tar.gz
            fi
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull existing images
          command: |
            set +e
            docker pull localhost:5000/ubuntu
            success=$?
            set -e
            if [[ "$success" = "0" ]]; then
                echo "Pulling from local registry"
                docker tag localhost:5000/ubuntu ubuntu:xenial-20191010
                docker pull localhost:5000/niworkflows
                docker tag localhost:5000/niworkflows niworkflows:latest
            else
                echo "Pulling from Docker Hub"
                docker pull ubuntu:xenial-20191010
                docker tag ubuntu:xenial-20191010 localhost:5000/ubuntu
                docker push localhost:5000/ubuntu
            fi

      - checkout
      - run:
          name: Build Docker image & push to registry
          no_output_timeout: 60m
          command: |
            e=1 && for i in {1..5}; do
              docker build --rm --cache-from=niworkflows:latest \
                -t niworkflows:latest \
                --build-arg BUILD_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ"` \
                --build-arg VCS_REF=`git rev-parse --short HEAD` . \
              && e=0 && break || sleep 15
            done && [ "$e" -eq "0" ]
            docker tag niworkflows:latest localhost:5000/niworkflows
            docker push localhost:5000/niworkflows
      - run:
          name: Docker registry garbage collection
          command: |
            docker exec -it registry /bin/registry garbage-collect --delete-untagged \
                /etc/docker/registry/config.yml
      - save_cache:
          key: build-v1-{{ .Branch }}-{{ epoch }}
          paths:
            - /tmp/docker
            - /tmp/images

  get_data:
    machine:
      # Ubuntu 14.04 with Docker 17.10.0-ce
      image: ubuntu-1604:202007-01
    working_directory: /home/circleci/data
    steps:
      - restore_cache:
          keys:
            - data-v1-{{ epoch }}
            - data-v1-
      - run:
          name: Get test data from ds000003
          command: |
            mkdir -p /tmp/data
            if [[ ! -d /tmp/data/ds003_downsampled ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                -O ds003_downsampled.tar.gz "https://files.osf.io/v1/resources/fvuh8/providers/osfstorage/57f328f6b83f6901ef94cf70"
              tar xvzf ds003_downsampled.tar.gz -C /tmp/data/
            else
              echo "Dataset ds000003 was cached"
            fi
      - run:
          name: Get BIDS test data stub
          command: |
            mkdir -p /tmp/data
            if [[ ! -d /tmp/data/BIDS-examples-1-enh-ds054 ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                -O BIDS-examples-1-enh-ds054.zip "http://github.com/chrisfilo/BIDS-examples-1/archive/enh/ds054.zip"
              unzip BIDS-examples-1-enh-ds054.zip -d /tmp/data/
            else
              echo "BIDS stub was cached"
            fi
      - run:
          name: Store FreeSurfer license file
          command: |
            mkdir -p /tmp/fslicense
            cd /tmp/fslicense
            echo "cHJpbnRmICJrcnp5c3p0b2YuZ29yZ29sZXdza2lAZ21haWwuY29tXG41MTcyXG4gKkN2dW12RVYzelRmZ1xuRlM1Si8yYzFhZ2c0RVxuIiA+IGxpY2Vuc2UudHh0Cg==" | base64 -d | sh
      - persist_to_workspace:
          root: /tmp
          paths:
            - data
            - fslicense
      - save_cache:
         key: data-v1-{{ epoch }}
         paths:
            - /tmp/data

  get_regression_data:
    machine:
      # Ubuntu 14.04 with Docker 17.10.0-ce
      image: ubuntu-1604:202007-01
    working_directory: /home/circleci/data
    steps:
      - restore_cache:
          keys:
            - regression-v5-{{ .Revision }}
            - regression-v5-
      - run:
          name: Get truncated BOLD series
          command: |
            mkdir -p /tmp/data
            if [[ ! -d /tmp/data/fmriprep_bold_truncated ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                -O fmriprep_bold_truncated.tar.gz "https://osf.io/286yr/download"
              tar xvzf fmriprep_bold_truncated.tar.gz -C /tmp/data/
            else
              echo "Truncated BOLD series were cached"
            fi
      - run:
          name: Get pre-computed masks
          command: |
            if [[ ! -d /tmp/data/fmriprep_bold_mask ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                -O fmriprep_bold_mask.tar.gz "https://osf.io/s4f7b/download"
              tar xvzf fmriprep_bold_mask.tar.gz -C /tmp/data/
            else
              echo "Pre-computed masks were cached"
            fi
      - save_cache:
         key: regression-v5-{{ .Revision }}-{{ epoch }}
         paths:
            - /tmp/data

  test_pytest:
    machine:
      image: ubuntu-1604:202007-01
    working_directory: /tmp/tests
    steps:
      - attach_workspace:
          at: /tmp
      - checkout:
          path: /tmp/src/niworkflows
      - run:
          name: Get codecov
          command: python -m pip install codecov
      - restore_cache:
          keys:
            - build-v1-{{ .Branch }}-{{ epoch }}
            - build-v1-{{ .Branch }}-
            - build-v1-master-
            - build-v1-
      - run:
          name: Docker authentication
          command: |
            if [[ -n $DOCKER_PASS ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
            fi
      - run:
          name: Set up Docker registry
          command: |
            if [[ -f /tmp/images/registry.tar.gz ]]; then
              echo "Loading saved registry image"
              docker load < /tmp/images/registry.tar.gz
            else
              echo "Pulling registry image from DockerHub"
              docker pull registry:2
            fi
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images to registry
          command: |
            docker pull localhost:5000/niworkflows
            docker tag localhost:5000/niworkflows niworkflows:latest
      - run:
          name: Run unit tests
          no_output_timeout: 2h
          command: |
            mkdir -p $PWD/artifacts $PWD/summaries
            sudo setfacl -d -m group:ubuntu:rwx $PWD
            sudo setfacl -m group:ubuntu:rwx $PWD
            docker run -u $( id -u ) -it --rm=false -w /src/niworkflows \
              -e COVERAGE_FILE=/tmp/summaries/.pytest.coverage \
              -e TEST_DATA_HOME=/data -v /tmp/data:/data \
              -e FS_LICENSE=/etc/fslicense.txt \
              -v /tmp/fslicense/license.txt:/etc/fslicense.txt:ro \
              -v ${PWD}:/tmp niworkflows:latest \
              pytest --junit-xml=/tmp/summaries/pytest.xml \
                     --cov niworkflows --cov-report xml:/tmp/summaries/unittests.xml \
                     --ignore=niworkflows/tests/ \
                     --ignore=niworkflows/func/tests/ \
                     niworkflows/

      - run:
          name: Submit unit test coverage
          command: |
            cd /tmp/src/niworkflows
            python -m codecov --file /tmp/tests/summaries/unittests.xml \
                --flags unittests -e CIRCLE_JOB

      - run:
          name: Run reportlet tests
          no_output_timeout: 2h
          command: |
            docker run -u $( id -u ) -it --rm=false -w /src/niworkflows \
              -e COVERAGE_FILE=/tmp/summaries/.reportlets.coverage \
              -e SAVE_CIRCLE_ARTIFACTS="/tmp/artifacts/" \
              -e TEST_DATA_HOME=/data -v /tmp/data:/data \
              -v /tmp/fslicense/license.txt:/opt/freesurfer/license.txt:ro \
              -v ${PWD}:/tmp niworkflows:latest \
              pytest -n auto --junit-xml=/tmp/summaries/reportlets.xml \
                     --cov niworkflows --cov-report xml:/tmp/summaries/reportlets.xml \
                     niworkflows/tests/
      - run:
          name: Submit reportlet test coverage
          command: |
            cd /tmp/src/niworkflows
            python -m codecov --file /tmp/tests/summaries/reportlets.xml \
                --flags reportlettests -e CIRCLE_JOB

      - run:
          name: Clean up tests directory
          command: |
            rm -rf /tmp/tests/pytest-of-root

      - store_artifacts:
          path: /tmp/tests/artifacts

      - store_test_results:
          path: /tmp/tests/summaries/

  test_masks:
    machine:
      image: ubuntu-1604:202007-01
    working_directory: /tmp/masks
    steps:
      - attach_workspace:
          at: /tmp
      - restore_cache:
          keys:
            - build-v1-{{ .Branch }}-{{ epoch }}
            - build-v1-{{ .Branch }}-
            - build-v1-master-
            - build-v1-
      - run:
          name: Docker authentication
          command: |
            if [[ -n $DOCKER_PASS ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
            fi
      - run:
          name: Set up Docker registry
          command: |
            if [[ -f /tmp/images/registry.tar.gz ]]; then
              echo "Loading saved registry image"
              docker load < /tmp/images/registry.tar.gz
            else
              echo "Pulling registry image from DockerHub"
              docker pull registry:2
              mkdir -p /tmp/images
              docker save registry:2 | gzip > /tmp/images/registry.tar.gz
            fi
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images to registry
          command: |
            docker pull localhost:5000/niworkflows
            docker tag localhost:5000/niworkflows niworkflows:latest

      - restore_cache:
          keys:
            - regression-v5-{{ .Revision }}
      - restore_cache:
          keys:
            - masks-workdir-v3-{{ .Branch }}-{{epoch}}
            - masks-workdir-v3-{{ .Branch }}-
            - masks-workdir-v3-master-
            - masks-workdir-v3-
      - run:
          name: Run regression tests on EPI masks
          no_output_timeout: 2h
          command: |
            mkdir -p /tmp/masks/{reports,workdir} && \
            docker run -ti -u $(id -u) -w /src/niworkflows \
              -e COVERAGE_FILE=/tmp/masks/reports/.coverage \
              -v /tmp/data:/tmp/data -v /tmp/masks/reports:/tmp/masks/reports \
              -e FMRIPREP_REGRESSION_SOURCE=/tmp/data/fmriprep_bold_truncated \
              -e FMRIPREP_REGRESSION_TARGETS=/tmp/data/fmriprep_bold_mask \
              -e FMRIPREP_REGRESSION_REPORTS=/tmp/masks/reports \
              -e CACHED_WORK_DIRECTORY=/tmp/work -v /tmp/masks/workdir:/tmp/work \
              niworkflows:latest \
              coverage run -p --rcfile=setup.cfg \
                     -m pytest --junit-xml=/tmp/masks/reports/regression.xml \
                     niworkflows/func/tests/
      - run:
          name: Clear reports folder & delete plot generator cache
          command: |
            pushd reports/
            tar cvfz fmriprep_bold_mask.tar.gz fmriprep_bold_mask/*/*.nii.gz
            rm -rf /tmp/masks/reports/fmriprep_bold_mask/
            popd
            find workdir/ -name "mask_diff_plot" -exec rm -rf {} +
      - store_artifacts:
          path: /tmp/masks/reports
      - store_test_results:
          path: /tmp/masks/reports
      - save_cache:
         key: masks-workdir-v3-{{ .Branch }}-{{ epoch }}
         paths:
            - /tmp/masks/workdir

      - run:
          name: Coverage preparation
          command: |
            docker run -ti -u $(id -u) -w /tmp/masks/reports \
              -e COVERAGE_FILE=/tmp/masks/reports/.coverage \
              -v /tmp/masks/reports:/tmp/masks/reports \
              niworkflows:latest coverage combine
            docker run -ti -u $(id -u) -w /tmp/masks/reports \
              -e COVERAGE_FILE=/tmp/masks/reports/.coverage \
              -v /tmp/masks/reports:/tmp/masks/reports \
              niworkflows:latest coverage xml -o coverage.xml
      - checkout:
          path: /tmp/src/niworkflows
      - run:
          name: Get codecov
          command: python -m pip install codecov
      - run:
          name: Submit masks test coverage
          working_directory: /tmp/src/niworkflows
          command: |
            cp /tmp/masks/reports/coverage.xml .
            sed -i "s+/src/niworkflows+/tmp/src/niworkflows+g" coverage.xml
            python -m codecov --file coverage.xml --flags masks -e CIRCLE_JOB

  test_package:
    docker:
      - image: circleci/python:3.8.5
    working_directory: /tmp/src/niworkflows
    steps:
      - checkout
      - run:
          name: Install build depends
          command: python -m pip install "setuptools>=40.8.0" "pip>=19" "twine<2.0" docutils
      - run:
          name: Build and check
          command: |
            python setup.py sdist
            python -m twine check dist/*
      - run:
          name: Validate version
          command: |
            THISVERSION=$( python get_version.py )
            python -m pip install dist/*.tar.gz
            mkdir empty
            cd empty
            INSTALLED=$( python -c 'import niworkflows; print(niworkflows.__version__)' )
            test "${CIRCLE_TAG:-$THISVERSION}" == "$INSTALLED"

  deploy_pypi:
    docker:
      - image: circleci/python:3.8.5
    working_directory: /tmp/src/niworkflows
    steps:
      - checkout
      - run:
          name: Install build depends
          command: python -m pip install "setuptools>=40.8.0" "pip>=19" "twine<2.0" docutils
      - run:
          name: Build and check
          command: |
            python setup.py check -r -s
            python setup.py sdist
            python -m twine check dist/*
      - run:
          name: Validate version
          command: |
            THISVERSION=$( python3 get_version.py )
            python -m pip install dist/*.tar.gz
            mkdir empty
            cd empty
            INSTALLED=$( python -c 'import niworkflows; print(niworkflows.__version__)' )
            test "${CIRCLE_TAG:-$THISVERSION}" == "$INSTALLED"
      - run:
          name: Upload to PyPi
          command: |
            python -m twine upload dist/*

  deploy_docker:
    machine:
      image: ubuntu-1604:202007-01
    working_directory: /tmp/src/
    steps:
      - restore_cache:
          keys:
            - build-v1-{{ .Branch }}-{{ epoch }}
            - build-v1-{{ .Branch }}-
            - build-v1-master-
            - build-v1-
          paths:
            - /tmp/docker
            - /tmp/images
      - run:
          name: Docker authentication
          command: |
            if [[ -n $DOCKER_PASS ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
            fi
      - run:
          name: Set up Docker registry
          command: |
            if [[ -f /tmp/images/registry.tar.gz ]]; then
              echo "Loading saved registry image"
              docker load < /tmp/images/registry.tar.gz
            else
              echo "Pulling registry image from DockerHub"
              docker pull registry:2
            fi
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images from local registry
          command: |
            docker pull localhost:5000/niworkflows
            docker tag localhost:5000/niworkflows nipreps/niworkflows:latest
      - run:
          name: Deploy to Docker Hub
          no_output_timeout: 40m
          command: |
            if [[ -n "$DOCKER_PASS" ]]; then
              docker login -u $DOCKER_USER -p $DOCKER_PASS
              docker push nipreps/niworkflows:latest
              docker tag nipreps/niworkflows nipreps/niworkflows:$CIRCLE_TAG
              docker push nipreps/niworkflows:$CIRCLE_TAG
            fi

  build_docs:
    docker:
      - image: circleci/python:3.8.5
    environment:
      - FSLOUTPUTTYPE: NIFTI
      - SUBJECTS_DIR: /tmp/subjects
    steps:
      - restore_cache:
          keys:
            - docs-v1-{{ .Branch }}-{{ .Revision }}
            - docs-v1-{{ .Branch }}-
            - docs-v1-master
            - docs-v1-
          paths:
            - ./docs/_build/_html
      - checkout
      - run:
          name: Create subjects folder
          command: mkdir -p $SUBJECTS_DIR
      - run:
          name: Install Graphviz
          command: sudo apt update && sudo apt -y install graphviz
      - run:
          name: Install deps
          command: python -m pip install --no-cache-dir -r docs/requirements.txt
      - run:
          name: Build only this commit
          command: make -C docs SPHINXOPTS="-W" BUILDDIR="_build/no_version_html" html
      - store_artifacts:
          path: ./docs/_build/no_version_html
      - run:
          name: Install niworkflows
          command: |
            python -m pip install --no-cache-dir codecov
            python -m pip install --no-cache-dir .[all]
      - run:
          name: Build only this commit with coverage collection
          command: |
            make -C docs/ clean
            export COVERAGE_FILE=/tmp/.coverage
            coverage run --source=niworkflows $( which sphinx-build ) \
                -b html -W -d docs/_build/no_version_doctrees ./docs/ docs/_build/no_version_html
            coverage xml -o /tmp/documentation.xml
            python -m codecov --file /tmp/documentation.xml --flags documentation -e CIRCLE_JOB
      - run:
          name: Uninstall NiWorkflows
          command: |
            python -m pip uninstall -y niworkflows
      - run:
          name: Generate Versioned Docs
          command: |
            set +e
            force_versioned="$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[docs?[ _]?versions?\]' )"
            set -e
            if [[ "x${CIRCLE_TAG}" = "x" && "${CIRCLE_BRANCH}" != "master" && "x${force_versioned}" = "x" ]]; then
              echo "Not a tag or master branch - skipping versioned docs."
              circleci step halt
            else
              make -C docs/ clean
              make -f ./docs/Makefile versioned CURBRANCH=${CIRCLE_TAG:-$CIRCLE_BRANCH}
            fi
      - save_cache:
          key: docs-v1-{{ .Branch }}-{{ .Revision }}
          paths:
            - ./docs/_build/_html
      - persist_to_workspace:
          root: docs/_build
          paths: html
      - store_artifacts:
          path: ./docs/_build/html

  deploy_docs_tag:
    <<: *docs

  deploy_docs_master:
    <<: *docs


workflows:
  version: 2
  build_test_deploy:
    jobs:
      - build:
          filters:
            tags:
              only: /.*/
      - get_data:
          filters:
            branches:
              ignore:
                - /masks?\/.*/
            tags:
              only: /.*/

      - get_regression_data:
          filters:
            branches:
              only:
                - /master/
                - /masks?\/.*/
            tags:
              ignore: /.*/

      - test_package:
          filters:
            branches:
              ignore:
                - /masks?\/.*/
            tags:
              only: /.*/

      - test_pytest:
          requires:
            - build
            - get_data
          filters:
            branches:
              ignore:
                - /docs?\/.*/
                - /masks?\/.*/
            tags:
              only: /.*/

      - test_masks:
          requires:
            - build
            - get_regression_data
          filters:
            branches:
              only:
                - /master/
                - /masks?\/.*/
            tags:
              ignore: /.*/

      - deploy_pypi:
          requires:
            - test_pytest
            - test_package
            - build_docs
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - deploy_docker:
          requires:
            - deploy_pypi
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - build_docs:
          filters:
            branches:
              ignore:
                - /tests?\/.*/
                - /ds005\/.*/
                - /ds054\/.*/
            tags:
              only: /.*/

      - deploy_docs_master:
          requires:
            - test_pytest
            - test_package
            - build_docs
          filters:
            branches:
              only: /master/
            tags:
              ignore: /.*/

      - deploy_docs_tag:
          requires:
            - deploy_docker
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
