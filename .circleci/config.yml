docs_deploy: &docs
  docker:
    - image: node:8.10.0
  steps:
    - run:
        name: Check whether this is the original repo
        command: |
          if [[ "$CIRCLE_PROJECT_USERNAME" != "nipreps" ]]; then
              echo "Not in nipreps/niworkflows - skipping docs deploy."
              circleci step halt
          fi
    - checkout
    - attach_workspace:
        at: docs/_build
    - run:
        name: Disable jekyll builds
        command: touch docs/_build/html/.nojekyll
    - run:
        name: Install and configure dependencies
        command: |
          npm install -g --silent gh-pages@3.0.0
          git config user.email "nipreps@gmail.com"
          git config user.name "Documentation Push"
    - add_ssh_keys:
        fingerprints:
          - "c8:a8:55:7d:1e:08:92:c2:86:29:7b:b4:4b:88:24:51"
    - run:
        name: Deploy docs to gh-pages branch
        command: gh-pages --no-history --dotfiles --message "doc(update) [skip ci]" --dist docs/_build/html

version: 2.1
orbs:
  docker: circleci/docker@1.6.0

jobs:
  build:
    machine:
      # https://discuss.circleci.com/t/linux-machine-executor-images-2021-april-q2-update/39928
      # upgrade Docker version
      image: ubuntu-2004:202104-01
    working_directory: /tmp/src/niworkflows
    environment:
      TZ: "/usr/share/zoneinfo/America/Los_Angeles"
      SCRATCH: "/scratch"
    steps:
      - restore_cache:
          keys:
            - build-v1-{{ .Branch }}-{{ .Revision }}
            - build-v1--{{ .Revision }}
            - build-v1-{{ .Branch }}-
            - build-v1-master-
            - build-v1-
          paths:
            - /tmp/docker
            - /tmp/images
      - run:
          name: Docker authentication
          command: |
            if [[ -n $DOCKER_PAT ]]; then
              echo "$DOCKER_PAT" | docker login -u $DOCKER_USER --password-stdin
            fi
      - run:
          name: Set up Docker registry
          command: |
            if [[ -f /tmp/images/registry.tar.gz ]]; then
              echo "Loading saved registry image"
              docker load < /tmp/images/registry.tar.gz
            else
              echo "Pulling registry image from DockerHub"
              docker pull registry:2
              mkdir -p /tmp/images
              docker save registry:2 | gzip > /tmp/images/registry.tar.gz
            fi
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull existing images
          command: |
            set +e
            docker pull localhost:5000/ubuntu
            success=$?
            set -e
            if [[ "$success" = "0" ]]; then
                echo "Pulling from local registry"
                docker tag localhost:5000/ubuntu ubuntu:focal-20210416
                docker pull localhost:5000/niworkflows
                docker tag localhost:5000/niworkflows niworkflows:latest
            else
                echo "Pulling from Docker Hub"
                docker pull ubuntu:focal-20210416
                docker tag ubuntu:focal-20210416 localhost:5000/ubuntu
                docker push localhost:5000/ubuntu
            fi

      - checkout
      - run:
          name: Build Docker image & push to registry
          no_output_timeout: 60m
          command: |
            e=1 && for i in {1..5}; do
              docker build --rm --cache-from=niworkflows:latest \
                -t niworkflows:latest \
                --build-arg BUILD_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ"` \
                --build-arg VCS_REF=`git rev-parse --short HEAD` \
                --build-arg VERSION=`python3 get_version.py` . \
              && e=0 && break || sleep 15
            done && [ "$e" -eq "0" ]
            docker tag niworkflows:latest localhost:5000/niworkflows
            docker push localhost:5000/niworkflows
      - run:
          name: Docker registry garbage collection
          command: |
            docker exec -it registry /bin/registry garbage-collect --delete-untagged \
                /etc/docker/registry/config.yml
      - save_cache:
          key: build-v1-{{ .Branch }}-{{ .Revision }}
          paths:
            - /tmp/docker
            - /tmp/images

  get_data:
    docker:
      - image: continuumio/miniconda3:4.9.2-alpine
    working_directory: /tmp/data
    environment:
      - TEMPLATEFLOW_HOME: /tmp/templateflow
    steps:
      - restore_cache:
          keys:
            - env-v1-{{ .Branch }}-
            - env-v1-master-
            - env-v1-
      - run:
          name: Setup git-annex, DataLad & TemplateFlow
          command: |
            conda install -y -c anaconda -c conda-forge git-annex datalad wget
            python -m pip install --no-cache-dir -U datalad-osf
            git config --global user.name 'NiPreps Bot'
            git config --global user.email 'nipreps@gmail.com'
            python -m pip install --no-cache-dir -U templateflow
      - save_cache:
          key: env-v1-{{ .Branch }}-{{ .BuildNum }}
          paths:
            - /opt/conda

      - restore_cache:
          keys:
            - data-v3-{{ .Branch }}-{{ epoch }}
            - data-v3-{{ .Branch }}-
            - data-v3-master-
            - data-v3-
      - run:
          name: Get test data from ds000003
          command: |
            if [[ ! -d ds000003 ]]; then
              datalad install -r https://github.com/nipreps-data/ds000003.git
            fi
            datalad update -r --merge -d ds000003/
            datalad get -J 2 -r -d ds000003/ ds000003/*

      - run:
          name: Get test data from ds000030
          command: |
            if [[ ! -d ds000030 ]]; then
              datalad install -r https://github.com/nipreps-data/ds000030.git
            fi
            datalad update -r --merge -d ds000030/
            datalad get -J 2 -r -d ds000030/ ds000030/sub-10228/func/*

      - run:
          name: Get BIDS test data stub
          command: |
            mkdir -p /tmp/data
            if [[ ! -d /tmp/data/BIDS-examples-1-enh-ds054 ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                -O BIDS-examples-1-enh-ds054.zip "http://github.com/chrisfilo/BIDS-examples-1/archive/enh/ds054.zip"
              unzip BIDS-examples-1-enh-ds054.zip -d /tmp/data/
            else
              echo "BIDS stub was cached"
            fi
      - save_cache:
         key: data-v3-{{ .Branch }}-{{ epoch }}
         paths:
            - /tmp/data/ds000003
            - /tmp/data/ds000030
            - /tmp/data/BIDS-examples-1-enh-ds054
      - run:
          name: Store FreeSurfer license file
          command: |
            mkdir -p /tmp/fslicense
            cd /tmp/fslicense
            echo "cHJpbnRmICJrcnp5c3p0b2YuZ29yZ29sZXdza2lAZ21haWwuY29tXG41MTcyXG4gKkN2dW12RVYzelRmZ1xuRlM1Si8yYzFhZ2c0RVxuIiA+IGxpY2Vuc2UudHh0Cg==" | base64 -d | sh

      - checkout:
          path: /tmp/src/niworkflows

      - persist_to_workspace:
          root: /tmp
          paths:
            - fslicense
            - src/

      - run:
          name: Check if regression data must be downloaded
          command: |
            cd /tmp/src/niworkflows
            set +e
            test_masks="$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[test[ _]?masks?\]' )$( echo $CIRCLE_BRANCH | grep -i -E '^masks?/' )"
            set -e
            if [[ "x${CIRCLE_TAG}" = "x" && "${CIRCLE_BRANCH}" != "master" && "x${test_masks}" = "x" ]]; then
              echo "Not a tag or master branch, not a ``masks?/`` branch, no ``[test_masks]`` label in commit message"
              echo "Skipping download of test data for mask regressions."
              circleci step halt
            fi

      - restore_cache:
          keys:
            - mask-regressions-v0-{{ .Branch }}-{{ .Revision }}-
            - mask-regressions-v0-{{ .Branch }}-
            - mask-regressions-v0-master-
            - mask-regressions-v0-
            - mask-regressions-
      - run:
          name: Setup TemplateFlow
          command: |
            python -c "from templateflow import api as tfapi; \
                       tfapi.get('MNI152NLin2009cAsym', resolution=1, label='brain', suffix='probseg'); \
                       tfapi.get('MNI152NLin2009cAsym', resolution=2, desc='fMRIPrep', suffix='boldref'); \
                       tfapi.get('MNI152NLin2009cAsym', resolution=2, desc='brain', suffix='mask'); "
      - run:
          name: Install epi-references
          command: |
            if [[ ! -d epi-references ]]; then
              datalad install -r https://github.com/nipreps-data/epi-references.git
            fi
            datalad update -r --merge -d epi-references/
            datalad get -J 2 -r -d epi-references/ epi-references/*
      - save_cache:
          key: mask-regressions-v0-{{ .Branch }}-{{ .Revision }}-{{ epoch }}
          paths:
            - /tmp/templateflow
            - /tmp/data/epi-references

  test_pytest:
    machine:
      image: ubuntu-2004:202104-01
    working_directory: /tmp/tests
    steps:
      - attach_workspace:
          at: /tmp
      - run:
          name: Get codecov
          command: python -m pip install codecov
      - restore_cache:
          keys:
            - build-v1-{{ .Branch }}-{{ .Revision }}
            - build-v1--{{ .Revision }}
            - build-v1-{{ .Branch }}-
            - build-v1-master-
            - build-v1-
      - run:
          name: Docker authentication
          command: |
            if [[ -n $DOCKER_PAT ]]; then
              echo "$DOCKER_PAT" | docker login -u $DOCKER_USER --password-stdin
            fi
      - run:
          name: Set up Docker registry
          command: |
            if [[ -f /tmp/images/registry.tar.gz ]]; then
              echo "Loading saved registry image"
              docker load < /tmp/images/registry.tar.gz
            else
              echo "Pulling registry image from DockerHub"
              docker pull registry:2
            fi
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images from registry
          command: |
            docker pull localhost:5000/niworkflows
            docker tag localhost:5000/niworkflows niworkflows:latest

      - restore_cache:
          keys:
            - data-v3-{{ .Branch }}-{{ epoch }}
            - data-v3-{{ .Branch }}-
            - data-v3-master-
            - data-v3-

      - run:
          name: Run unit tests
          no_output_timeout: 2h
          command: |
            mkdir -p $PWD/artifacts $PWD/summaries
            docker run -u $( id -u ):$( id -g ) -it --rm -w /src/niworkflows \
              -e COVERAGE_FILE=/tmp/summaries/.pytest.coverage \
              -e TEST_DATA_HOME=/data -v /tmp/data:/data \
              -e FS_LICENSE=/etc/fslicense.txt \
              -v /tmp/fslicense/license.txt:/etc/fslicense.txt:ro \
              -v ${PWD}:/tmp niworkflows:latest \
              pytest --junit-xml=/tmp/summaries/pytest.xml \
                     --cov niworkflows --cov-report xml:/tmp/summaries/unittests.xml \
                     --ignore=niworkflows/tests/ \
                     --ignore=niworkflows/func/tests/ \
                     niworkflows/

      - run:
          name: Submit unit test coverage
          command: |
            cd /tmp/src/niworkflows
            python -m codecov --file /tmp/tests/summaries/unittests.xml \
                --flags unittests -e CIRCLE_JOB

      - run:
          name: Run reportlet tests
          no_output_timeout: 2h
          command: |
            docker run -u $( id -u ):$( id -g ) -it --rm -w /src/niworkflows \
              -e COVERAGE_FILE=/tmp/summaries/.reportlets.coverage \
              -e SAVE_CIRCLE_ARTIFACTS="/tmp/artifacts/" \
              -e TEST_DATA_HOME=/data -v /tmp/data:/data \
              -v /tmp/fslicense/license.txt:/opt/freesurfer/license.txt:ro \
              -v ${PWD}:/tmp niworkflows:latest \
              pytest -n auto --junit-xml=/tmp/summaries/reportlets.xml \
                     --cov niworkflows --cov-report xml:/tmp/summaries/reportlets.xml \
                     niworkflows/tests/
      - run:
          name: Submit reportlet test coverage
          command: |
            cd /tmp/src/niworkflows
            python -m codecov --file /tmp/tests/summaries/reportlets.xml \
                --flags reportlettests -e CIRCLE_JOB

      - run:
          name: Clean up tests directory
          command: |
            rm -rf /tmp/tests/pytest-of-root

      - store_artifacts:
          path: /tmp/tests/artifacts

      - store_test_results:
          path: /tmp/tests/summaries/

  test_masks:
    machine:
      image: ubuntu-2004:202104-01
    working_directory: /tmp/masks
    steps:
      - attach_workspace:
          at: /tmp

      - run:
          name: Determine whether regression tests (masks) must be executed
          command: |
            cd /tmp/src/niworkflows
            set +e
            test_masks="$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[test[ _]?masks?\]' )$( echo $CIRCLE_BRANCH | grep -i -E '^masks?/' )"
            set -e
            if [[ "x${CIRCLE_TAG}" = "x" && "${CIRCLE_BRANCH}" != "master" && "x${test_masks}" = "x" ]]; then
              echo "Not a tag or master branch, not a ``masks?/`` branch, no ``[test_masks]`` label in commit message"
              echo "Skipping download of test data for mask regressions."
              circleci step halt
            fi

      - restore_cache:
          keys:
            - mask-regressions-v0-{{ .Branch }}-{{ .Revision }}-
            - mask-regressions-v0-{{ .Branch }}-

      - restore_cache:
          keys:
            - build-v1-{{ .Branch }}-{{ .Revision }}
            - build-v1--{{ .Revision }}
            - build-v1-{{ .Branch }}-
            - build-v1-master-
            - build-v1-
      - run:
          name: Docker authentication
          command: |
            if [[ -n $DOCKER_PAT ]]; then
              echo "$DOCKER_PAT" | docker login -u $DOCKER_USER --password-stdin
            fi
      - run:
          name: Set up Docker registry
          command: |
            if [[ -f /tmp/images/registry.tar.gz ]]; then
              echo "Loading saved registry image"
              docker load < /tmp/images/registry.tar.gz
            else
              echo "Pulling registry image from DockerHub"
              docker pull registry:2
              mkdir -p /tmp/images
              docker save registry:2 | gzip > /tmp/images/registry.tar.gz
            fi
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images to registry
          command: |
            docker pull localhost:5000/niworkflows
            docker tag localhost:5000/niworkflows niworkflows:latest
      - restore_cache:
          keys:
            - masks-workdir-v5-{{ .Branch }}-{{epoch}}
            - masks-workdir-v5-{{ .Branch }}-
            - masks-workdir-v5-master-
            - masks-workdir-v5-
      - run:
          name: Run regression tests on EPI masks
          no_output_timeout: 2h
          command: |
            mkdir -p /tmp/masks/{reports,workdir} && \
            docker run -ti -u $(id -u) -w /src/niworkflows \
              -v /tmp/templateflow:/templateflow \
              -v /tmp/data/epi-references:/data -v /tmp/masks/reports:/tmp/masks/reports \
              -e COVERAGE_FILE=/tmp/masks/reports/.coverage \
              -e TEMPLATEFLOW_HOME=/templateflow -e TEMPLATEFLOW_AUTOUPDATE=off \
              -e FMRIPREP_REGRESSION_SOURCE=/data \
              -e FMRIPREP_REGRESSION_REPORTS=/tmp/masks/reports \
              -e CACHED_WORK_DIRECTORY=/tmp/work -v /tmp/masks/workdir:/tmp/work \
              -v /tmp/fslicense/license.txt:/opt/freesurfer/license.txt:ro \
              niworkflows:latest \
              coverage run -p --rcfile=setup.cfg \
                     -m pytest --junit-xml=/tmp/masks/reports/regression.xml \
                     niworkflows/func/tests/
      - run:
          name: Clear reports folder & delete plot generator cache
          command: |
            pushd reports/
            tar cvfz fmriprep_bold_mask.tar.gz fmriprep_bold_mask/*/*.nii.gz
            rm -rf /tmp/masks/reports/fmriprep_bold_mask/
            popd
            find workdir/ -name "mask_diff_plot" -exec rm -rf {} +
      - store_artifacts:
          path: /tmp/masks/reports
      - store_test_results:
          path: /tmp/masks/reports
      - save_cache:
         key: masks-workdir-v5-{{ .Branch }}-{{ epoch }}
         paths:
            - /tmp/masks/workdir

      - run:
          name: Coverage preparation
          command: |
            docker run -ti -u $(id -u) -w /tmp/masks/reports \
              -e COVERAGE_FILE=/tmp/masks/reports/.coverage \
              -v /tmp/masks/reports:/tmp/masks/reports \
              niworkflows:latest coverage combine
            docker run -ti -u $(id -u) -w /tmp/masks/reports \
              -e COVERAGE_FILE=/tmp/masks/reports/.coverage \
              -v /tmp/masks/reports:/tmp/masks/reports \
              niworkflows:latest coverage xml -o coverage.xml
      - run:
          name: Get codecov
          command: python -m pip install codecov
      - run:
          name: Submit masks test coverage
          working_directory: /tmp/src/niworkflows
          command: |
            cp /tmp/masks/reports/coverage.xml .
            sed -i "s+/src/niworkflows+/tmp/src/niworkflows+g" coverage.xml
            python -m codecov --file coverage.xml --flags masks -e CIRCLE_JOB

  test_package:
    docker:
      - image: circleci/python:3.8.5
    working_directory: /tmp/src/niworkflows
    steps:
      - checkout
      - run:
          name: Install build depends
          command: python -m pip install "setuptools>=40.8.0" "pip>=19" "twine<2.0" docutils
      - run:
          name: Build and check
          command: |
            python setup.py sdist
            python -m twine check dist/*
      - run:
          name: Validate version
          command: |
            THISVERSION=$( python get_version.py )
            python -m pip install dist/*.tar.gz
            mkdir empty
            cd empty
            INSTALLED=$( python -c 'import niworkflows; print(niworkflows.__version__)' )
            test "${CIRCLE_TAG:-$THISVERSION}" == "$INSTALLED"

  deploy_pypi:
    docker:
      - image: circleci/python:3.8.5
    working_directory: /tmp/src/niworkflows
    steps:
      - checkout
      - run:
          name: Install build depends
          command: python -m pip install "setuptools>=40.8.0" "pip>=19" "twine<2.0" docutils
      - run:
          name: Build and check
          command: |
            python setup.py check -r -s
            python setup.py sdist
            python -m twine check dist/*
      - run:
          name: Validate version
          command: |
            THISVERSION=$( python3 get_version.py )
            python -m pip install dist/*.tar.gz
            mkdir empty
            cd empty
            INSTALLED=$( python -c 'import niworkflows; print(niworkflows.__version__)' )
            test "${CIRCLE_TAG:-$THISVERSION}" == "$INSTALLED"
      - run:
          name: Upload to PyPi
          command: |
            python -m twine upload dist/*

  deploy_docker:
    machine:
      image: ubuntu-2004:202104-01
    working_directory: /tmp/src/
    steps:
      - restore_cache:
          keys:
            - build-v1-{{ .Branch }}-{{ .Revision }}
            - build-v1--{{ .Revision }}
            - build-v1-{{ .Branch }}-
            - build-v1-master-
            - build-v1-
          paths:
            - /tmp/docker
            - /tmp/images
      - run:
          name: Docker authentication
          command: |
            if [[ -n $DOCKER_PAT ]]; then
              echo "$DOCKER_PAT" | docker login -u $DOCKER_USER --password-stdin
            fi
      - run:
          name: Set up Docker registry
          command: |
            if [[ -f /tmp/images/registry.tar.gz ]]; then
              echo "Loading saved registry image"
              docker load < /tmp/images/registry.tar.gz
            else
              echo "Pulling registry image from DockerHub"
              docker pull registry:2
            fi
            docker run -d -p 5000:5000 --restart=always --name=registry \
                -v /tmp/docker:/var/lib/registry registry:2
      - run:
          name: Pull images from local registry
          command: |
            docker pull localhost:5000/niworkflows
            docker tag localhost:5000/niworkflows nipreps/niworkflows:latest
      - run:
          name: Deploy to Docker Hub
          no_output_timeout: 40m
          command: |
            docker push nipreps/niworkflows:latest
            docker tag nipreps/niworkflows nipreps/niworkflows:$CIRCLE_TAG
            docker push nipreps/niworkflows:$CIRCLE_TAG

  build_docs:
    docker:
      - image: circleci/python:3.8.5
    environment:
      - FSLOUTPUTTYPE: NIFTI
      - SUBJECTS_DIR: /tmp/subjects
    steps:
      - restore_cache:
          keys:
            - docs-v1-{{ .Branch }}-{{ .Revision }}
            - docs-v1-{{ .Branch }}-
            - docs-v1-master
            - docs-v1-
          paths:
            - ./docs/_build/_html
      - checkout
      - run:
          name: Create subjects folder
          command: mkdir -p $SUBJECTS_DIR
      - run:
          name: Install Graphviz
          command: sudo apt update && sudo apt -y install graphviz
      - run:
          name: Install deps
          command: |
            python -m pip install --no-cache-dir -U "pip>=20.3"
            python -m pip install --no-cache-dir -r docs/requirements.txt
      - run:
          name: Build only this commit
          command: make -C docs SPHINXOPTS="-W" BUILDDIR="_build/no_version_html" html
      - store_artifacts:
          path: ./docs/_build/no_version_html
      - run:
          name: Find undocumented Python objects
          command: |
            make -C docs docs-coverage
            cat docs/_build/coverage/python.txt
      - store_artifacts:
          path: ./docs/_build/coverage

      # - run:
      #     name: Install niworkflows
      #     command: |
      #       python -m pip install --no-cache-dir codecov
      #       python -m pip install --no-cache-dir .[all]
      # - run:
      #     name: Build only this commit with coverage collection
      #     command: |
      #       make -C docs/ clean
      #       export COVERAGE_FILE=/tmp/.coverage
      #       coverage run --source=niworkflows $( which sphinx-build ) \
      #           -b html -W -d docs/_build/no_version_doctrees ./docs/ docs/_build/no_version_html
      #       coverage xml -o /tmp/documentation.xml
      #       python -m codecov --file /tmp/documentation.xml --flags documentation -e CIRCLE_JOB

      - run:
          name: Generate Versioned Docs
          command: |
            set +e
            force_versioned="$( git log --format=oneline -n 1 $CIRCLE_SHA1 | grep -i -E '\[docs?[ _]?versions?\]' )"
            set -e
            if [[ "x${CIRCLE_TAG}" = "x" && "${CIRCLE_BRANCH}" != "master" && "x${force_versioned}" = "x" ]]; then
              echo "Not a tag or master branch - skipping versioned docs."
              circleci step halt
            else
              python -m pip uninstall -y niworkflows
              make -C docs/ clean
              make -f ./docs/Makefile versioned CURBRANCH=${CIRCLE_TAG:-$CIRCLE_BRANCH}
            fi
      - save_cache:
          key: docs-v1-{{ .Branch }}-{{ .Revision }}
          paths:
            - ./docs/_build/_html
      - persist_to_workspace:
          root: docs/_build
          paths: html
      - store_artifacts:
          path: ./docs/_build/html

  deploy_docs_tag:
    <<: *docs

  deploy_docs_master:
    <<: *docs


workflows:
  version: 2
  build_test_deploy:
    jobs:
      - build:
          filters:
            tags:
              only: /.*/
      - get_data:
          filters:
            tags:
              only: /.*/

      - test_package:
          filters:
            branches:
              ignore:
                - /masks?\/.*/
            tags:
              only: /.*/

      - test_pytest:
          requires:
            - build
            - get_data
          filters:
            branches:
              ignore:
                - /docs?\/.*/
                - /masks?\/.*/
            tags:
              only: /.*/

      - test_masks:
          requires:
            - build
            - get_data
          filters:
            tags:
              ignore: /.*/

      - deploy_pypi:
          requires:
            - test_pytest
            - test_package
            - build_docs
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - deploy_docker:
          requires:
            - deploy_pypi
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/

      - build_docs:
          filters:
            branches:
              ignore:
                - /tests?\/.*/
                - /ds005\/.*/
                - /ds054\/.*/
            tags:
              only: /.*/

      - deploy_docs_master:
          requires:
            - test_pytest
            - test_package
            - build_docs
          filters:
            branches:
              only: /master/
            tags:
              ignore: /.*/

      - deploy_docs_tag:
          requires:
            - deploy_docker
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
